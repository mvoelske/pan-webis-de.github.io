---
layout: default
nav_active: tasks
title: PAN @ CLEF 2012 - Plagiarism Detection
description: PAN @ CLEF 2012 - Plagiarism Detection
---

<main>
    <header class="uk-section uk-section-muted">
        <nav class="uk-container">
            <div class="uk-align-right uk-visible@m uk-text-muted">
                <a class="uk-button" href="{{ 'clef11/pan11-web/plagiarism-detection.html' | relative_url }}"
                   data-uk-icon="chevron-left"></a>
                CLEF 2012
                <a class="uk-button uk-padding-remove-right"
                   href="{{ 'clef13/pan13-web/plagiarism-detection.html' | relative_url }}"
                   data-uk-icon="chevron-right"></a>
            </div>

            <ul class="uk-text-muted uk-tab uk-margin-remove-top">
                <li><a href="{{ '/clef12/pan12-web/index.html' | relative_url }}">Overview</a></li>
                <li><a href="{{ '/clef12/pan12-web/keynotes.html' | relative_url }}">Keynotes</a></li>
                <li><a href="{{ '/clef12/pan12-web/program.html' | relative_url }}">Program</a></li>
                <li class="uk-active">
                    <a href="#">Tasks <span class="uk-margin-small-left"
                                            data-uk-icon="icon: chevron-down"></span></a>
                    <div class="uk-dropdown" data-uk-dropdown="mode: click">
                        <ul class="uk-nav uk-dropdown-nav">
                            <li><a href="{{ '/clef12/pan12-web/author-identification.html' | relative_url }}">Author
                                Identification</a></li>
                            <li>
                                <a href="{{ '/clef12/pan12-web/wikipedia-quality-flaw-prediction.html' | relative_url }}">Wikipedia
                                    Quality Flaw Prediction</a></li>
                            <li class="uk-active"><a
                                    href="{{ '/clef12/pan12-web/plagiarism-detection.html' | relative_url }}">Plagiarism
                                Detection</a></li>
                        </ul>
                    </div>
                </li>
                <li><a href="{{ '/clef12/pan12-web/submission.html' | relative_url }}">Submission</a></li>
                <li><a href="{{ '/clef12/pan12-web/proceedings.html' | relative_url }}">Proceedings</a></li>
            </ul>
        </nav>

        <div class="uk-container uk-margin-small">
            {% include current-register-quicklink.html year=2012 %}
            <h1 class="uk-margin-small">Plagiarism Detection</h1>
            <div class="page-header-meta">PAN @ CLEF 2012</div>
        </div>

        <div class="uk-container uk-margin-medium">
            <p class="uk-text-lead">This task is divided into <a href="#source-retrieval">source retrieval</a> and
                <a href="# text-alignment"> text alignment</a>. You can choose to solve one or both of
                them.</p>
        </div>
    </header>

    <section>
        <div class="uk-section">
            <div class="uk-container">
                <div class="uk-column-1-2@l uk-text-justify">
                    <h2 id="source-retrieval">Source Retrieval</h2>

                    <h3>Task</h3>
                    <p>
                        Given a suspicious document and a web search API, your task is to retrieve all plagiarized
                        sources while minimizing retrieval costs.
                    </p>

                    <h3>Training Corpus</h3>
                    <p>
                        To develop your software, we provide you with a training corpus that consists of suspicious
                        documents. Each suspicious document is about a specific topic and may consist of plagiarized
                        passages obtained from web pages on that topic found in the ClueWeb09 corpus.
                    </p>
                    <p>
                        <a class="uk-button uk-button-primary"
                           href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2012f.pdf">Learn more
                            »</a>
                        <a class="uk-button uk-button-primary" target="_blank"
                           href="https://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-12/pan12-data/pan12-source-retrieval-training-corpus-2014-12-01.zip">Download
                            corpus</a>
                    </p>

                    <h3>API</h3>
                    <p>If you are not in possession of the <a href="http://www.lemurproject.org/clueweb09.php/"
                                                              target="_blank">ClueWeb09 corpus</a>, we also provide
                        access to two search engines which index the ClueWeb, namely the <a
                                href="http://www.lemurproject.org/indri/" target="_blank">Lemur Indri search engine</a>
                        and the <a href="http://chatnoir.webis.de" target="_blank">ChatNoir search engine</a>. To
                        programmatically access these two search engines, we provide a unified search API.</p>
                    <p><a class="uk-button uk-button-primary" href="http://webis12.medien.uni-weimar.de/pan/">Learn more
                        »</a></p>
                    <p><strong>Note:</strong> To better separate the source retrieval task from the text alignment task,
                        the API provides a text alignment oracle feature. For each document you request to download from
                        the ClueWeb, the text alignment oracle discloses if this document is a source for plagiarism for
                        the suspicious document in question. In addition, the plagiarized text is returned. This, way
                        participation in the source retrieval task does not require the development of a text alignment
                        solution. However, you are free to use your own text alignment, if you want to.</p>


                    <h3>Baseline</h3>
                    <p>For your convenience, we provide a baseline program written in Python.</p>
                    <p><a class="uk-button uk-button-primary"
                          href="../../clef12/pan12-code/pan12-source-retrieval-baseline.py">Download
                        program</a></p>
                    <p>The program loops through the suspicious documents in a given directory and outputs a search
                        interaction log. The log is valid with respect to the output format described below. You may use
                        the source code for getting started with your own approach.</p>

                    <h3>Output</h3>
                    <p>For each suspicious document <code>suspicious-documentXYZ.txt</code> found in the evaluation
                        corpora, your plagiarism detector shall output an interaction log <code>suspicious-documentXYZ.log</code>
                        which logs meta information about your retrieval process:</p>
                    <pre class="prettyprint lang-py" style="overflow-x:auto;white-space:nowrap">
Timestamp&nbsp;&nbsp;&nbsp;[Query|Download_URL]<br/>
1258326592&nbsp;&nbsp;barack obama family tree<br/>
1258326597&nbsp;&nbsp;http://webis15.medien.uni-weimar.de/chatnoir/clueweb?id=110212744<br/>
1258326598&nbsp;&nbsp;http://webis15.medien.uni-weimar.de/chatnoir/clueweb?id=10221241<br/>
1258326599&nbsp;&nbsp;http://webis15.medien.uni-weimar.de/chatnoir/clueweb?id=100003305377<br/>
1258326605&nbsp;&nbsp;barack obama genealogy<br/>
1258326610&nbsp;&nbsp;http://webis15.medien.uni-weimar.de/chatnoir/clueweb?id=82208332<br/>
...
</pre>
                    <p>For example, the above file would specify that at 1258326592 (Unix timestamp) the query <code>barack
                        obama family tree</code> was sent and that in the following three of the retrieved documents
                        were selected for download before the next query was sent.</p>


                    <h3>Performance Measures</h3>
                    <p>
                        Performance will be measured based on the following five scores as averages over each suspicious
                        document:
                    </p>
                    <ol>
                        <li>
                            Number of queries submitted.
                        </li>
                        <li>
                            Number of web pages downloaded.
                        </li>
                        <li>
                            Precision and recall of web pages downloaded regarding actual sources of a suspicious
                            document.
                        </li>
                        <li>
                            Number of queries until the first actual source is found.
                        </li>
                        <li>
                            Number of downloads until the first actual source is downloaded.
                        </li>
                    </ol>
                    <p>
                        Measures 1-3 capture the overall behavior of a system and measures 4-5 assess the time to first
                        result. The quality of identifying reused passages between documents is not taken into account
                        here, but note that retrieving duplicates of a source document is considered a true positive,
                        whereas retrieving more than one duplicate of a source document does not improve performance.
                    </p>
                    <p>
                        <a class="uk-button uk-button-primary"
                           href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2012h.pdf#page=6">Learn
                            more »</a>
                    </p>

                    <h3>Test Corpus</h3>
                    <p>Once you finished tuning your approach to achieve satisfying performance on the training corpus,
                        you should run your software on the test corpus.</p>
                    <p>During the competition, the test corpus will not be released publicly. Instead, we ask you to
                        submit your software for evaluation at our site as described below.</p>
                    <p>After the competition, the test corpus is available including ground truth data. This way, you
                        have all the necessities to evaluate your approach on your own, yet being comparable to those
                        who took part in the competition.</p>
                    <p>
                        <a class="uk-button uk-button-primary" target="_blank"
                           href="https://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-12/pan12-data/pan12-source-retrieval-test-corpus1-2014-12-01.zip">Download
                            corpus 1</a>
                        <a class="uk-button uk-button-primary" target="_blank"
                           href="https://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-12/pan12-data/pan12-source-retrieval-test-corpus2-2014-12-01.zip">Download
                            corpus 2</a>
                    </p>


                    <h3>Submission</h3>
                    <p>We ask you to prepare your software so that it can be executed via a command line call. You can
                        choose freely among the available programming languages and among the operating systems
                        Microsoft Windows 7 and Ubuntu 12.04. We will ask you to deploy your software onto a virtual
                        machine that will be made accessible to you after registration. You will be able to reach the
                        virtual machine via ssh and via remote desktop. Please test your software using one of the
                        unit-test-scripts below. Download the script, fill in the required fields, and start it using
                        the sh command. If the script runs without errors and if the correct output is produced, you can
                        submit your software by sending your unit-test-script via e-mail to <a
                                href="mailto:pan@webis.de">pan@webis.de</a>. For more information see the user guide
                        below.</p>
                    <p>
                        <a class="uk-button uk-button-primary" href="pan12-virtual-machine-user-guide.pdf">PAN User
                            Guide »</a>
                        <a class="uk-button uk-button-primary" href="../pan12-code/unit-test-ta-windows.sh">Unit-Test
                            Windows »</a>
                        <a class="uk-button uk-button-primary" href="../pan12-code/unit-test-ta-ubuntu.sh">Unit-Test
                            Ubuntu »</a>
                    </p>
                    <p><strong>Note:</strong> By submitting your software you retain full copyrights. You agree to grant
                        us usage rights only for the purpose of the PAN competition. We agree not to share your software
                        with a third party or use it for other purposes than the PAN competition.</p>

                    <h3>Results</h3>
                    <p>The following table lists the performances achieved by the participating teams:</p>
                    <table class="uk-table uk-table-divider uk-table-small uk-table-hover" style="font-size:small;">
                        <thead>
                        <tr class="top">
                            <th colspan="5" style="text-align:center">Source Retrieval Performance</th>
                        </tr>
                        <tr class="top2">
                            <th colspan="2" style="text-align:center">Workload to 1st Detection</th>
                            <th colspan="2" style="text-align:center">Downloaded Sources</th>
                            <th>Team</th>
                        </tr>
                        <tr class="mid">
                            <th>Queries</th>
                            <th>Downloads</th>
                            <th>Precision</th>
                            <th>Recall</th>
                            <th></th>
                        </tr>
                        </thead>
                        <tbody>
                        <tr>
                            <td> 4.47</td>
                            <td> 25.88</td>
                            <td>0.0182</td>
                            <td><b>0.5567</b></td>
                            <td>L. Gillam, N. Newbold, and N. Cooke<br/>University of Surrey, UK</td>
                        </tr>
                        <tr>
                            <td> 8.78</td>
                            <td> 13.50</td>
                            <td>0.0709</td>
                            <td>0.4342</td>
                            <td>A. Jayapal<br/>University of Sheffield, UK</td>
                        </tr>
                        <tr>
                            <td>80.59</td>
                            <td> 27.47</td>
                            <td>0.0178</td>
                            <td>0.3742</td>
                            <td>L. Kong°, H. Qi°, S. Wang°, C. Du*, S. Wang*, and Y. Han°<br/>°Heilongjiang Institute of
                                Technology and *Harbin Engineering University, China
                            </td>
                        </tr>
                        <tr>
                            <td>27.28</td>
                            <td>318.94</td>
                            <td>0.0025</td>
                            <td>0.2133</td>
                            <td>Y. Palkovskii and A. Belov<br/>Zhytomyr State University, Ukraine</td>
                        </tr>
                        <tr>
                            <td><b> 1.53</b></td>
                            <td><b> 6.28</b></td>
                            <td><b>0.0813</b></td>
                            <td>0.3513</td>
                            <td>&Scaron;. Suchomel, J. Kasprzak, and M. Brandejs<br/>Masaryk University, Czech Republic
                            </td>
                        </tr>
                        </tbody>
                    </table>
                    <p>A more detailed analysis of the retrieval performances can be found in the overview paper
                        accompanying this task.</p>
                    <p><a class="uk-button uk-button-primary"
                          href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2012t.pdf#page=13">Learn
                        more »</a></p>
                </div>
            </div>
        </div>  <!-- section -->
    </section>

    <section>
        <div class="uk-section">
            <div class="uk-container">
                <div class="uk-column-1-2@l uk-text-justify">
                    <h2 id="text-alignment">Text Alignment
                    </h2>

                    <h3>Task</h3>
                    <p>Given a pair of documents, your task is to identify all contiguous maximal-length passages of
                        reused text between them.</p>


                    <h3>Training Corpus</h3>
                    <p>To develop your software, we provide you with a training corpus that consists of pairs of
                        documents, one of which may contain passages of text resued from the other. The reused text is
                        subject to various kinds of (automatic) obfuscation to hide the fact it has been reused.</p>
                    <p>
                        <a class="uk-button uk-button-primary"
                           href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2010p.pdf#page=4">Learn
                            more »</a>
                        <a class="uk-button uk-button-primary" target="_blank"
                           href="https://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-12/pan12-data/pan12-text-alignment-training-corpus-2012-03-16.zip">Download
                            corpus</a>
                    </p>


                    <h3>Baseline</h3>
                    <p>For your convenience, we provide a baseline program written in Python.</p>
                    <p><a class="uk-button uk-button-primary"
                          href="https://pan.webis.de/clef12/pan12-code/pan12-text-alignment-baseline.py">Download
                        program</a></p>
                    <p>The program loops through the document pairs of a corpus and records the detection results in XML
                        files. The XML files are valid with respect to the output format described below. You may use
                        the source code for getting started with your own approach.</p>

                    <h3>Output</h3>
                    <p>Enclosed in the evaluation corpora, a file named <code>pairs</code> is found, which lists all
                        pairs of suspicious documents and source documents to be compared. For each pair <code>suspicious-documentXYZ.txt</code>
                        and <code>source-documentABC.txt</code>, your plagiarism detector shall output an XML file
                        <code>suspicious-documentXYZ-source-documentABC.xml</code> which contains meta information about
                        the plagiarism cases detected within:</p>
                    <pre class="prettyprint lang-xml" style="overflow-x:auto"><nobr>&lt;document reference="suspicious-documentXYZ.txt"&gt;</nobr>
&lt;feature
  name="detected-plagiarism"
  this_offset="5"
  this_length="1000"
&nbsp;&nbsp;<nobr>source_reference="source-documentABC.txt"</nobr>
  source_offset="100"
  source_length="1000"
/&gt;
&lt;feature ... /&gt;
...
&lt;/document&gt;</pre>
                    <p>For example, the above file would specify an aligned passage of text between <code>suspicious-documentXYZ.txt</code>
                        and <code>source-documentABC.txt</code>, and that it is of length 1000 characters, starting at
                        character offset 5 in the suspicious document and at character offset 100 in the source
                        document.</p>

                    <h3>Performance Measures</h3>
                    <p>Performance will be measured using macro-averaged precision and recall, granularity, and the
                        plagdet score, which is a combination of the first three measures. For your convenience, we
                        provide a reference implementation of the measures written in Python.</p>
                    <p>
                        <a class="uk-button uk-button-primary"
                           href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2010p.pdf#page=2">Learn
                            more »</a>
                        <a class="uk-button uk-button-primary"
                           href="../../sepln09/pan09-code/pan09-plagiarism-detection-performance-measures.py">Download
                            measures</a>
                    </p>

                    <h3>Test Corpus</h3>
                    <p>Once you finished tuning your approach to achieve satisfying performance on the training corpus,
                        you should run your software on the test corpus.</p>
                    <p>During the competition, the test corpus will not be released publicly. Instead, we ask you to
                        submit your software for evaluation at our site as described below.</p>
                    <p>After the competition, the test corpus is available including ground truth data. This way, you
                        have all the necessities to evaluate your approach on your own, yet being comparable to those
                        who took part in the competition.</p>
                    <p>
                        <a class="uk-button uk-button-primary" target="_blank"
                           href="https://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-12/pan12-data/pan12-text-alignment-test-corpus-2012-08-12.zip">Download
                            corpus</a>
                    </p>

                    <h3>Submission</h3>
                    <p>We ask you to prepare your software so that it can be executed via a command line call. You can
                        choose freely among the available programming languages and among the operating systems
                        Microsoft Windows 7 and Ubuntu 12.04. We will ask you to deploy your software onto a virtual
                        machine that will be made accessible to you after registration. You will be able to reach the
                        virtual machine via ssh and via remote desktop.</p>

                    <p><strong>Note:</strong> By submitting your software you retain full copyrights. You agree to grant
                        us usage rights only for the purpose of the PAN competition. We agree not to share your software
                        with a third party or use it for other purposes than the PAN competition.</p>


                    <h3>Results</h3>
                    <p>The following table lists the performances achieved by the participating teams:</p>
                    <table class="uk-table uk-table-divider uk-table-small uk-table-hover" style="font-size:small;">
                        <thead>
                        <tr>
                            <th colspan="2" style="text-align:center">Text Alignment Performance</th>
                        </tr>
                        <tr>
                            <th>Plagdet</th>
                            <th>Team</th>
                        </tr>
                        </thead>
                        <tbody>
                        <tr>
                            <td>0.7386159</td>
                            <td>L. Kong°, H. Qi°, S. Wang°, C. Du*, S. Wang*, and Y. Han°<br/>°Heilongjiang Institute of
                                Technology and *Harbin Engineering University, China
                            </td>
                        </tr>
                        <tr>
                            <td>0.6826726</td>
                            <td>&Scaron;. Suchomel, J. Kasprzak, and M. Brandejs<br/>Masaryk University, Czech Republic
                            </td>
                        </tr>
                        <tr>
                            <td>0.6787810</td>
                            <td>Cristian Grozea° and Marius Popescu*<br/>°Fraunhofer FOKUS, Germany, and *University of
                                Bucharest, Romania
                            </td>
                        </tr>
                        <tr>
                            <td>0.6735574</td>
                            <td>Oberreuter et al.<br/>Universidad de Chile, Chile</td>
                        </tr>
                        <tr>
                            <td>0.6252024</td>
                            <td>D.A. Rodr&iacute;guez Torrej&oacute;n and J.M. Mart&iacute;n Ramos<br/>Universidad de
                                Huelva, Spain
                            </td>
                        </tr>
                        <tr>
                            <td>0.5382163</td>
                            <td>Y. Palkovskii and A. Belov<br/>Zhytomyr State University, Ukraine</td>
                        </tr>
                        <tr>
                            <td>0.3499632</td>
                            <td>R. K&uuml;ppers and S. Conrad<br/>University of D&uuml;sseldorf, Germany</td>
                        </tr>
                        <tr>
                            <td>0.3099853</td>
                            <td>F. S&aacute;nchez-Vega, M. Montes-y-G&oacute;mez, and L. Villase&ntilde;or-Pineda<br/>Instituto
                                Nacional de Astrof&iacute;sica, &Oacute;ptica y Electr&oacute;nica, Mexico
                            </td>
                        </tr>
                        <tr>
                            <td>0.3088109</td>
                            <td>L. Gillam, N. Newbold, and N. Cooke<br/>University of Surrey, UK</td>
                        </tr>
                        <tr>
                            <td>0.0452519</td>
                            <td>A. Jayapal<br/>The University of Sheffield, UK</td>
                        </tr>
                        </tbody>
                    </table>
                    <p>A more detailed analysis of the detection performances can be found in the overview paper
                        accompanying this task.</p>
                    <p>
                        <a class="btn btn-default"
                           href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2012h.pdf#page=18">Learn
                            more »</a>
                    </p>


                    <h3>Related Work</h3>
                    <p>
                        For an overview of approaches to plagiarism detection, we would like to refer you to the
                        proceedings of the past three plagiarism detection competitions:
                    <ul>
                        <li>
                            <a href="../../clef11/pan11-web/about.html#proceedings">PAN @ CLEF'11</a> (<a
                                href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2011t.pdf">overview
                            paper</a>),
                        </li>
                        <li>
                            <a href="../../clef10/pan10-web/about.html#proceedings">PAN @ CLEF'10</a> (<a
                                href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2010t.pdf">overview
                            paper</a>), and
                        </li>
                        <li>
                            <a href="../../sepln09/pan09-web/about.html#proceedings">PAN @ SEPLN'09</a> (<a
                                href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2009e.pdf">overview
                            paper</a>).
                        </li>
                    </ul>
                    </p><p>
                    For an overview of the TIRA evaluation platform visit <a href="http://tira.webis.de">http://tira.webis.de</a>.
                    <p/>
                </div>
            </div>
        </div>  <!-- section -->

        <div class="uk-section uk-section-muted">
            <div class="uk-container">

                <h2>Task Chair</h2>
                <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                    {% include people-cards/potthast.html %}
                </div>

                <h2>Task Committee</h2>
                <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                    {% include people-cards/gollub.html %}
                    {% include people-cards/hagen.html %}
                    {% include people-cards/stein.html %}
                    {% include people-cards/temporary.html url="https://weimar.webis.de"
                    name="Jan Graßegger" picture="../pan12-figures/jan.jpg" affiliation="Bauhaus Universität Weimar"  %}
                    {% include people-cards/kiesel.html %}
                    {% include people-cards/temporary.html url="https://weimar.webis.de"
                    name="Maximilian Michel" picture="../pan12-figures/maximilian.jpg" affiliation="Bauhaus Universität Weimar"  %}
                    {% include people-cards/temporary.html url="https://weimar.webis.de"
                    name="Arnd Oberländer" picture="../pan12-figures/arnd.jpg" affiliation="Bauhaus Universität Weimar"  %}
                    {% include people-cards/temporary.html url="https://weimar.webis.de"
                    name="Martin Tippmann" picture="../pan12-figures/martint.jpg" affiliation="Bauhaus Universität Weimar"  %}
                    {% include people-cards/rosso.html %}
                    {% include people-cards/gupta.html %}
                    {% include people-cards/barron-cedeno.html %}
                </div>
            </div>
            <div class="uk-container uk-padding-large uk-padding-remove-bottom">
                {% include organizations/clef-organizations-section.html year=2012 %}
            </div>
        </div>
    </section>
</main>
