<!DOCTYPE html>
<html lang="en">
<head>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>PAN 2014</title> 

<link href="../../css/bootstrap.min.css" rel="stylesheet" />
<link href="../../css/prettify.css" rel="stylesheet" />

<style>
.navbar .navbar-nav {
  font-weight: bold;
}
</style>

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
  <script src="../../js/html5shiv.js"></script>
  <script src="../../js/respond.min.js"></script>
<![endif]-->

<link rel="shortcut icon" href="../pan14-figures/pan-icon-16x16.ico">
<!--
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="ico/apple-touch-icon-144-precomposed.png">
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="ico/apple-touch-icon-114-precomposed.png">
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="ico/apple-touch-icon-72-precomposed.png">
<link rel="apple-touch-icon-precomposed" href="ico/apple-touch-icon-57-precomposed.png">
-->

</head>
<body>

<nav class="navbar navbar-inverse navbar-static-top" role="navigation">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="../../index.html"><img src="../pan14-figures/pan-logo-small-lightgrey.png" alt="PAN" style="margin-top:-5px"></a>
  </div>
  <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
    <ul class="nav navbar-nav navbar-right">
      <li><a href="../../index.html">Home</a></li>
      <li><a href="index.html">PAN @ CLEF 2014:</a></li>
      <li><a href="about.html">About</a></li>
      <li><a href="proceedings.html">Proceedings</a></li>
      <li class="dropdown active">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Tasks <span class="caret"></span></a>
        <ul class="dropdown-menu">
          <li><a href="plagiarism-detection.html">Plagiarism Detection</a></li>
          <li class="active"><a href="author-identification.html">Author Identification</a></li>
          <li><a href="author-profiling.html">Author Profiling</a></li>
        </ul>
      </li>
    </ul>
  </div>
</nav>

<div class="container">


<div id="task-description" class="row">
  <div class="col-xs-12">
    <h1 id="task-description" class="page-header">
      Author Identification
      <div class="btn-group">
        <a role="button" class="btn btn-default" href="../../clef13/pan13-web/author-identification.html"><span class="glyphicon glyphicon-chevron-left" style="color:grey;"></span></a>
        <span role="button" class="btn btn-default" disabled="disabled">2014</span>
        <a role="button" class="btn btn-default" href="../../clef15/pan15-web/author-identification.html"><span class="glyphicon glyphicon-chevron-right" style="color:grey;"></span></a>
      </div>
    </h1>
    <p>Authorship attribution is an important problem in many areas including 
	information retrieval and computational linguistics, but also in applied 
	areas such as law and journalism where knowing the author of a document 
	(such as a ransom note) may be able to save lives. The most common framework 
	for testing candidate algorithms is a text classification problem: given 
	known sample documents from a small, finite set of candidate authors, which 
	if any wrote a questioned document of unknown authorship? It has been 
	commented, however, that this may be an unreasonably easy task. A more 
	demanding problem is author verification where given a set of documents by a 
	single author and a questioned document, the problem is to determine if the 
	questioned document was written by that particular author or not. This may 
	more accurately reflect real life in the experiences of professional 
	forensic linguists, who are often called upon to answer this kind of 
	question. It is the second year PAN focuses on the so-called author 
	verification problem.</p>
    <p><strong>A note to forensic linguists:</strong> In order to bridge the gap between linguistics and computer science, we strongly encourage submissions from researchers from both fields. We understand that research groups with expertise in linguistics use manual or semi-automated methods and, therefore, they are not able to submit their software. To enable their participation, we will provide them with the opportunity to analyze the test corpus after the deadline of software submission (mid-April). Their results will be ranked in a separate list with respect to the performance of the software submissions and they will be entitled to describe their approach in a paper.<span lang="en-gb"> 
	In this framework, any scholar or research group with expertise in 
	linguistics wishing to participate should contact the Task Chair.</span></p>
    <div class="panel panel-default">
      <div class="panel-heading">Task</div>
      <div class="panel-body">Given a small set (no more than 5, possibly as few as one) of "known" documents by a single person and a "questioned" document, the task is to determine whether the questioned document was written by the same person who wrote the known document set.</div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Training Corpus</div>
      <div class="panel-body">
        <p>To develop your software, we provide you with a training corpus that comprises a set of author verification problems in several languages/genres. Each problem consists of some (up to five) known documents by a single person and exactly one questioned document. All documents within a single problem instance will be in the same language and best efforts are applied to assure that within-problem documents are matched for genre, register, theme, and date of writing. The document lengths vary from a few hundred to a few thousand words.</p>
        <p><a class="btn btn-default" target="_blank" href="http://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-14/pan14-data/pan14-authorship-verification-training-corpus-2014-04-22.zip">Download corpus</a> (updated April 22, 2014)</p>
		    <p>The documents of each problem are located in a separate folder, the name of which (problem ID) encodes the language/genre of the documents. The following list shows the available languages/genres, their codes, and examples of problem IDs:</p>
		    <table class="table table-condensed rule" style="font-size:small;">
          <thead>
            <tr><th>Language</th><th>Genre</th><th>Code</th><th>Problem IDs</th></tr>
          </thead>
          <tbody>
            <tr><td>Dutch</td><td>essays</td><td>DE</td><td>DE001, DE002,	DE003, etc.</td></tr>
            <tr><td>Dutch</td><td>reviews</td><td>DR</td><td>DR001, DR002, DR003, etc.</td></tr>
            <tr><td>English</td><td>essays</td><td>EE</td><td>EE001, EE002,	EE003, etc.</td></tr>
            <tr><td>English</td><td>novels</td><td>EN</td><td>EN001, EN002, EN003, etc.</td></tr>
            <tr><td>Greek</td><td>articles</td><td>GR</td><td>GR001, GR002, GR003, etc.</td></tr>
            <tr><td>Spanish</td><td>articles</td><td>SP</td><td>SP001, SP002, SP003, etc.</td></tr>
          </tbody>
        </table>
        <p>The ground truth data of the training corpus found in the file <code>truth.txt</code> include one line per problem with problem ID and the correct binary answer (Y means the known and the questioned documents are by the same author and N means the opposite). For example:</p>
        <pre class="prettyprint lang-py" style="overflow-x:auto">EN001 N
EN002 Y
EN003 N
...
</pre>
</div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Output</div>
      <div class="panel-body"><p>Your software must take as input the absolute path to a set of problems. For each problem there is a separate sub-folder within that path including the set of known documents and the single unknown document of that problem (similarly to the training corpus). The software has to output a single text file <code>answers.txt</code> with all the produced answers for the whole set of evaluation problems. Each line of this file corresponds to a problem instance, it starts with the ID of the problem followed by a score, a real number in [0,1] inclusive, corresponding to the probability of a positive answer. That is, 0 means it is absolutely sure the questioned document is not by the author of the known documents, 1.0 means it is absolutely sure the questioned document and the known documents are by the same author, and 0.5 means that a positive and a negative answer are equally likely. The probability scores should be round with three decimal digits. Use a single whitespace to separate problem ID and probability score.<br/>
      For example, an <code>answers.txt</code> file may look like this:</p>
<pre class="prettyprint lang-py" style="overflow-x:auto">EN001 0.031
EN002 0.874
EN003 0.500
...
</pre>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Performance Measures</div>
      <div class="panel-body">
		    <p>The participants’ answers will be evaluated according to the area under the ROC curve (AUC) of their probability scores.</p>
		    <p>In addition, the performance of the binary classification results (automatically extracted from probability scores where every score greater than 0.5 corresponds to a positive answer, every score lower than 0.5 corresponds to a negative answer, while 0.5 corresponds to an unanswered problem, or an "I don’t know" answer) will be measured based on c@1 (<a href="http://www.aclweb.org/anthology/P11-1142.pdf">Pe&ntilde;as &amp; Rodrigo, 2011</a>):</p>
		    <ul>
		      <li>c@1 = (1/<i>n</i>)*(<i>n</i><sub>c</sub>+(<i>n</i><sub>u</sub>*<i>n</i><sub>c</sub>/<i>n</i>))</li>
		    </ul>
		    <p>where:</p>
		    <ul>
			    <li><i>n</i> = #problems</li>
			    <li><i>n</i><sub>c </sub>= #correct_answers</li>
			    <li><i>n</i><sub>u </sub>= #unanswered_problems</li>
		    </ul>
		    <p><b>Note:</b> when positive/negative answers are provided for all available problems (probability scores different than 0.5), then c@1=accuracy. However, c@1 rewards approaches that maintain the same number of correct answers and decrease the number of incorrect answers by leaving some problems unanswered (when probability score equals 0.5).</p>
		    <p>The final ranking of the participants will be based on the <b>product of AUC and c@1.</b></p>
		  </div>
		</div>
    <div class="panel panel-default">
      <div class="panel-heading">Test Corpus</div>
      <div class="panel-body">
        <p>Once you finished tuning your approach to achieve satisfying performance on the training corpus, your software will be tested on the evaluation corpus.</p>
        <p>During the competition, the evaluation corpus will not be released publicly. Instead, we ask you to submit your software for evaluation at our site as described below.</p>
        <p>After the competition, the evaluation corpus will become available including ground truth data. This way, you have all the necessities to evaluate your approach on your own, yet being comparable to those who took part in the competition.</p>
        <p>
          <a class="btn btn-default" target="_blank" href="http://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-14/pan14-data/pan14-authorship-verification-test-corpus1-2014-04-22.zip">Download corpus 1</a>
          <a class="btn btn-default" target="_blank" href="http://www.uni-weimar.de/medien/webis/corpora/corpus-pan-labs-09-today/pan-14/pan14-data/pan14-authorship-verification-test-corpus2-2014-04-22.zip">Download corpus 2</a>
        </p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Submission</div>
      <div class="panel-body">
        <p>We ask you to prepare your software so that it can be executed via command line calls. To maximize the sustainability of software submissions for this task, we encourage you to prepare your software so it can be re-trained on demand, i.e., by offering two commands, one for training, and one for testing. This way, your software can be reused on future evaluation corpora as well as on private collections submitted to PAN by via our data submission initiative.</p>
        <p>The training command shall take as input (i) an absolute path to a training corpus formated as described above, and (ii) an absolute path to an empty output directory:</p>
        <pre class="prettyprint lang-c" style="overflow-x:auto">
> myTrainingSoftware <b>-i</b> path/to/training/corpus <b>-o</b> path/to/output/directory
</pre>
        <p>Based on the training corpus, and perhaps based on its language and genre found within, your software shall train a classification model, and save the trained model to the specified output directory in serialized or binary form.</p>
        <p>The testing command shall take as input (i) an absolute path to a test corpus (not containing the ground truth) (ii) an absolute path to a previously trained classification model, and (iii) an absolute path to an empty output directory:</p>
        <pre class="prettyprint lang-py" style="overflow-x:auto">
> myTestingSoftware <b>-i</b> path/to/test/corpus <b>-m</b> path/to/classification/model <b>-o</b> path/to/output/directory
</pre>
        <p>Based on the classification model, the software shall classifiy each case found in the test corpus and write an output file as described above to the output directory.</p>
        <p>However, <b>offering a command for training is optional</b>, so if you face difficulties in doing so, you may skip the training command and omit the model option <b>-m</b> from the testing command.</p>
        <p>You can choose freely among the available programming languages and among the operating systems Microsoft Windows 7 and Ubuntu 12.04. We will ask you to deploy your software onto a virtual machine that will be made accessible to you after registration. You will be able to reach the virtual machine via ssh and via remote desktop. More information about how to access the virtual machines can be found in the user guide below</p>
        <p><a class="btn btn-default" href="pan14-virtual-machine-user-guide.pdf">PAN Virtual Machine User Guide »</a></p>
        <p>Once deployed in your virtual machine, your can move to submit your software. Before doing so, we provide your with a software submission readiness tester. Please use this tester to verify that your software works. Since we will be calling your software automatically in much the same ways as the tester does, this lowers the risk ot errors.</p>
        <p><a class="btn btn-default" href="../pan14-code/pan-software-submission-readiness-tester.zip">Download PAN Software Submission Readiness Tester</a></p>
        <p>When your software is submission-ready, please mail the filled out <code>submission.txt</code> file found along the software submission readiness tester to <a href="mailto:pan@webis.de">pan@webis.de</a>.</p>
        <p><strong>Note:</strong> By submitting your software you retain full copyrights. You agree to grant us usage rights only for the purpose of the PAN competition. We agree not to share your software with a third party or use it for other purposes than the PAN competition.</p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Contributions</div>
      <div class="panel-body">
        <p>For your convenience, we summarize the main contributions of the 2014 edition of the author identification task with respect to previous editions:</p>
        <p>Novelties:
        <ul>
          <li>The output of your software must be composed of real (probability) scores rather than binary Y/N answers</li>
          <li>The maximum number of documents of known authorship within a problem is 5 (instead of 10)</li>
          <li>The evaluation measures used for ranking are (ROC) AUC and c@1 instead of recall, precision and F1</li>
          <li>More languages/genres are represented in the corpus</li>
          <li>The training/evaluation corpora are larger</li>
          <li>It is possible (optionally) to submit a trainable version of your approach to be used with any given training corpus</li>
        </ul>
        </p>
        <p>Unchanged:
        <ul>
          <li>The task definition is the same</li>
          <li>The format of corpus and ground truth is the same</li>
          <li>The positive/negative problems are equally distributed</li>
        </ul>
        </p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Results</div>
      <div class="panel-body">
        <p>The following table lists the performances achieved by the participating teams:</p>
        <table class="table table-condensed rule" style="font-size:small;">
        <thead>
        <tr><th colspan="2" style="text-align:center">Authorship attribution performance</th></tr>
        <tr><th>FinalScore</th><th>Team</th></tr>
        </thead>
        <tbody>
        <tr><td>0.566</td><td>Meta Classifier</td></tr>
        <tr><td>0.490</td><td>Mahmoud Khonji and Youssef Iraqi<br/>Khalifa University, United Arab Emirates</td></tr>
        <tr><td>0.484</td><td>Jordan Fréry°, Christine Largeron°, and Mihaela Juganaru-Mathieu*<br/>°Université de Lyon and *École Nationale Supérieure des Mines, France</td></tr>
        <tr><td>0.461</td><td>Esteban Castillo°, Ofelia Cervantes°, Darnes Vilariño*, David Pinto*, and Saul León*<br/>°Universidad de las Américas Puebla and *Benemérita Universidad Autónoma de Puebla, Mexico</td></tr>
        <tr><td>0.451</td><td>Erwan Moreau, Arun Jayapal, and Carl Vogel<br/>Trinity College Dublin, Ireland</td></tr>
        <tr><td>0.450</td><td>Cristhian Mayor, Josue Gutierrez, Angel Toledo, Rodrigo Martinez, Paola Ledesma, Gibran Fuentes, and Ivan Meza<br/>Universidad Nacional Autonoma de Mexico, Mexico</td></tr>
        <tr><td>0.426</td><td>Hamed Zamani, Hossein Nasr, Pariya Babaie, Samira Abnar, Mostafa Dehghani, and Azadeh Shakery<br/>University of Tehran, Iran</td></tr>
        <tr><td>0.400</td><td>Satyam, Anand, Arnav Kumar Dawn, and Sujan Kumar Saha<br/>Birla Institute of Technology, India</td></tr>
        <tr><td>0.375</td><td>Pashutan Modaresi and Philipp Gross<br/>pressrelations GmbH, Germany</td></tr>
        <tr><td>0.367</td><td>Magdalena Jankowska, Vlado Kešelj, and Evangelos Milios<br/>Dalhousie University, Canada</td></tr>
        <tr><td>0.335</td><td>Oren Halvani and Martin Steinebach<br/>Fraunhofer Institute for Secure Information Technology SIT, Germany</td></tr>
        <tr><td>0.325</td><td>Baseline</td></tr>
        <tr><td>0.308</td><td>Anna Vartapetiance and Lee Gillam<br/>University of Surrey, UK</td></tr>
        <tr><td>0.306</td><td>Robert Layton<br/>Federation University, Australia</td></tr>
        <tr><td>0.304</td><td>Sarah Harvey<br/>University of Waterloo, Canada</td></tr>
        </tbody>
        </table>
        <p>A more detailed analysis of the detection performances can be found in the overview paper accompanying this task.</p>
        <p>
	        <a class="btn btn-default" href="http://www.uni-weimar.de/medien/webis/events/pan-14/pan14-papers-final/pan14-authorship-verification/stamatatos14-overview.pdf#page=9">Learn more »</a>
        </p>
      </div>
    </div>
    <div class="panel panel-default">
      <div class="panel-heading">Related Work</div>
      <div class="panel-body">
        <p>We refer you to:</p>
        <ul><li>
        <a href="../../clef13/pan13-web/about.html#proceedings">PAN @ CLEF'13</a> (<a href="http://www.uni-weimar.de/medien/webis/events/pan-13/pan13-papers-final/pan13-authorship-verification/juola13-overview.pdf">overview paper</a>)
        </li><li>
        <a href="../../clef12/pan12-web/about.html#proceedings">PAN @ CLEF'12</a> (<a href="http://www.uni-weimar.de/medien/webis/events/pan-12/pan12-papers-final/pan12-author-identification/juola12-overview.pdf">overview paper</a>)
        </li><li>
        <a href="../../clef11/pan11-web/about.html#proceedings">PAN @ CLEF'11</a> (<a href="http://www.uni-weimar.de/medien/webis/events/pan-11/pan11-papers-final/pan11-author-identification/juola11-overview.pdf">overview paper</a>)
        </li><li>
        Patrick Juola. <a href="http://portal.acm.org/citation.cfm?id=1373451">Authorship Attribution</a>. In Foundations and Trends in Information Retrieval, Volume 1, Issue 3, March 2008.
        </li><li>
        Moshe Koppel, Jonathan Schler, and Shlomo Argamon. <a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.20961/full">Computational Methods
        Authorship Attribution</a>. Journal of the American Society for Information Science and Technology, Volume 60, Issue 1, pages 9-26, January 2009.
        </li><li>
        Efstathios Stamatatos. <a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.21001/full">A Survey of Modern Authorship Attribution Methods</a>.
        Journal of the American Society for Information Science and Technology, Volume 60, Issue 3, pages 538-556, March 2009.
        </li></ul>
      </div>
    </div>
  </div>
</div>

<div id="task-committee" class="row" style="padding-top:60px;">
  <div class="col-xs-12">
    <h1 class="page-header">Task Chair</h1>
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-sm-3">
    <div class="thumbnail" style="text-align:center;">
      <a href="http://www.icsd.aegean.gr/lecturers/stamatatos/" target="_blank"><img src="../pan14-figures/stathis.jpg" class="img-rounded" alt="Efstathios Stamatatos"></a>
      <p><a href="http://www.icsd.aegean.gr/lecturers/stamatatos/" target="_blank">Efstathios Stamatatos</a></p>
      <p style="font-size:10pt">University of the Aegean</p>
    </div>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <h2>Task Committee</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-6 col-sm-3">
    <div class="thumbnail" style="text-align:center;">
      <a href="http://www.clips.uantwerpen.be/~walter/" target="_blank"><img src="../pan14-figures/walter.jpg" class="img-rounded" alt="Walter Daelemans"></a>
      <p style="white-space:nowrap"><a href="http://www.clips.uantwerpen.be/~walter/" target="_blank">Walter Daelemans</a></p>
      <p style="font-size:10pt">University of Antwerp</p>
    </div>
  </div>
  <div class="col-xs-6 col-sm-3">
    <div class="thumbnail" style="text-align:center;">
      <a href="http://www.mathcs.duq.edu/~juola/" target="_blank"><img src="../pan14-figures/patrick.jpg" class="img-rounded" alt="Patrick Juola"></a>
      <p style="white-space:nowrap"><a href="http://www.mathcs.duq.edu/~juola/" target="_blank">Patrick Juola</a></p>
      <p style="font-size:10pt">Duquesne University</p>
    </div>
  </div>
  <div class="col-xs-6 col-sm-3">
    <div class="thumbnail" style="text-align:center;">
      <a href="http://www.uni-weimar.de/medien/webis/people" target="_blank"><img src="../pan14-figures/martin.jpg" class="img-rounded" alt="Martin Potthast"></a>
      <p style="white-space:nowrap"><a href="http://www.uni-weimar.de/medien/webis/people" target="_blank">Martin Potthast</a></p>
      <p style="font-size:10pt">Bauhaus-Universit&auml;t Weimar</p>
    </div>
  </div>
  <div class="col-xs-6 col-sm-3">
    <div class="thumbnail" style="text-align:center;">
      <a href="http://www.webis.de" target="_blank"><img src="../pan14-figures/benno.jpg" class="img-rounded" alt="Benno Stein"></a>
      <p style="white-space:nowrap"><a href="http://www.webis.de" target="_blank">Benno Stein</a></p>
      <p style="font-size:10pt">Bauhaus-Universit&auml;t Weimar</p>
    </div>
  </div>
  <div class="col-xs-6 col-sm-3">
    <div class="thumbnail" style="text-align:center;">
      <a href="mailto:masp1988@hotmail.com" target="_blank"><img src="../pan14-figures/miguel.jpg" class="img-rounded" alt="Miguel Angel Sanchez Perez"></a>
      <p style="white-space:nowrap">
	  <a href="mailto:masp1988@hotmail.com">Miguel Angel S&aacute;nchez P&eacute;rez</a></p>
      <p style="font-size:10pt">National Polytechnic Institute, Mexico</p>
    </div>
  </div>
  <div class="col-xs-6 col-sm-3">
    <div class="thumbnail" style="text-align:center;">
      <a href="http://www.clips.uantwerpen.be/~ben/" target="_blank"><img src="../pan14-figures/ben.jpg" class="img-rounded" alt="Ben Verhoeven"></a>
      <p style="white-space:nowrap"><a href="http://www.clips.uantwerpen.be/~ben/" target="_blank">Ben Verhoeven</a></p>
      <p style="font-size:10pt">University of Antwerp</p>
    </div>
  </div>
  <div class="col-xs-6 col-sm-3">
    <div class="thumbnail" style="text-align:center;">
      <a href="http://www.lsi.upc.edu/~albarron/" target="_blank"><img src="../pan14-figures/alberto.jpg" class="img-rounded" alt="Alberto Barr&oacute;n-Cede&ntilde;o"></a>
      <p style="white-space:nowrap"><a href="http://www.lsi.upc.edu/~albarron/" target="_blank">Alberto Barr&oacute;n-Cede&ntilde;o</a></p>
      <p style="font-size:10pt">Universitat Polit&egrave;cnica de Catalunya</p>
    </div>
  </div>
</div>

<footer>
  <p class="pull-right">© pan.webis.de</p>
</footer>

</div> <!-- /container -->

<script src="../../js/jquery.js"></script>
<script src="../../js/bootstrap.min.js"></script>
<script src="../../js/prettify.js"></script>
<script>
  !function ($) {
    $(function(){
      window.prettyPrint && prettyPrint()   
    })
  }(window.jQuery)
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-70770005-1', 'auto');
  ga('send', 'pageview');

</script>

</body>
</html>

