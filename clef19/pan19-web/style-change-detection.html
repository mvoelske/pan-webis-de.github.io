---
layout: default
nav_active: tasks
title: PAN @ CLEF 2019 - Style Change Detection
description: PAN @ CLEF 2019 - Style Change Detection
---

<main>
    <header class="uk-section uk-section-muted">
        <nav class="uk-container">
            <div class="uk-align-right uk-text-muted">
                <a class="uk-button" href="{{ 'clef18/pan18-web/author-identification.html' | relative_url }}" data-uk-icon="chevron-left"></a>
                CLEF 2019
                <a class="uk-button uk-disabled uk-padding-remove-right" href="#"
                   data-uk-icon="chevron-right"></a>
            </div>

            <ul class="uk-text-muted uk-tab uk-margin-remove-top">
                <li><a href="{{ '/clef19/pan19-web/index.html' | relative_url }}">Overview</a></li>
                <li><a href="{{ '/clef19/pan19-web/submission.html' | relative_url }}">Submission</a></li>
                <li class="uk-active">
                    <a href="#">Tasks <span class="uk-margin-small-left" data-uk-icon="icon: chevron-down"></span></a>
                    <div class="uk-dropdown" data-uk-dropdown="mode: click">
                        <ul class="uk-nav uk-dropdown-nav">
                            <li><a href="{{ '/clef19/pan19-web/author-profiling.html' | relative_url }}">Bots and Gender Profiling</a></li>
                            <li><a href="{{ '/clef19/pan19-web/celebrity-profiling.html' | relative_url }}">Celebrity Profiling</a></li>
                            <li><a href="{{ '/clef19/pan19-web/author-identification.html' | relative_url }}">Cross-domain Authorship Attribution</a></li>
                            <li class="uk-active"><a href="{{ '/clef19/pan19-web/style-change-detection.html' | relative_url }}">Style Change Detection</a></li>
                        </ul>
                    </div>
                </li>
                <li><a href="{{ '/clef19/pan19-web/program.html' | relative_url }}">Program</a></li>
                <li><a href="{{ '/clef19/pan19-web/proceedings.html' | relative_url }}">Proceedings</a></li>
            </ul>
        </nav>

        <div class="uk-container uk-margin-small">
            <a class="uk-button uk-button-primary uk-align-right"
               href="https://docs.google.com/forms/d/e/1FAIpQLSfR_xoBuGU3q7o3EYPoItN28UPuZENjs3wlWYEX_EdRGUyRfA/viewform" target="_blank">
                Register now!
            </a>

            <h1 class="uk-margin-small">Style Change Detection</h1>
            <div class="page-header-meta">CLEF @ PAN 2019</div>
        </div>
    </header>

    <div class="uk-section">
        <div class="uk-container uk-column-1-2@l uk-text-justify">
            <h2>Introduction</h2>
            <p>Many approaches have been proposed recently to identify <i>the</i> author of a given document. Thereby, one fact
                is often silently assumed: i.e., that the given document is indeed written by only author.
                For a realistic author identification system it is therefore crucial to at first determine whether a document
                is single- or multiauthored.</p>
            <p>To this end, previous PAN editions aimed to analyze multi-authored documents. As it has been shown that it is a
                hard problem to reliably identify individual authors and their contribtuion within a single document (<a
                    href="../../clef16/pan16-web/author-identification.html">Author Diarization, 2016</a>;
                <a href="../../clef17/pan17-web/author-identification.html">Style Breach Detection, 2017</a>), last year's
                task substantially relaxed the problem by asking only for binary decision (single- or multi-authored).
                Considering the promising results achieved by the submitted approaches (see the
                <a href="../../clef18/pan18-web/proceedings.html">overview paper</a> for details), we continue last year's
                task and additionally ask participants to predict the number of involved authors.</p>

            <p>Given a document, participants thus should apply intrinsic style analyses to hierarchically answer
                the following questions:</p>

            <ol>
                <li>Is the document written by one or more authors, i.e., do style changes exist or not?</li>
                <li>If it is multi-authored, how many authors have collaborated?</li>
            </ol>

            <p>The following figure illustrates some possible scenarios and the expected output:</p>
            <img src="../pan19-figures/style-change-detection-19-example.png"/>

            <p>Note that it is irrelevant to identify the number of style changes or the specific positions where the authorships change.</p>

            <h2>Task</h2>
            <p>Given a document, determine whether it contains style changes or not, i.e., if it was written by
                a single or multiple authors. If it is written by more than one author, determine the number of involved collaborators.</p>
            <p>All documents are provided in English and may contain zero up to arbitrarily many style
                changes, resulting from arbitrarily many authors.</p>

            <h2>Development Phase</h2>
            <p>To develop your algorithms, a data set including corresponding solutions is provided.</p>
            <p><i>Details will be announced soon.</i></p>

            <p>To tackle the problem, you can develop novel approaches, extend existing algorithms from last year's task or
                adapt approaches from related problems such as <b>intrinsic plagiarism detection</b> or <b>text segmentation</b>.
                You are also free to additionally evaluate your approaches on last year's training/validation/test dataset
                (for the number of authors use the corresponding meta data).</p>

            <h2>Evaluation Phase</h2>
            <p>Once you finished tuning your approach to achieve satisfying performance on the training corpus,
                your software will be tested on the evaluation corpus (test data set). You can expect the test data
                set to be similar to the validation data set, i.e., also based on StackExchange user posts and of
                similar size as the validation set. During the competition, the evaluation corpus will not be
                released publicly. Instead, we ask you to <strong>submit your software</strong> for evaluation at
                our site as described below.</p>
            <p>After the competition, the evaluation corpus will become available including ground truth data.
                This way, you have all the necessities to evaluate your approach on your own, yet being comparable
                to those who took part in the competition.</p>

            <h2>Output</h2>
            <p>In general, the data structure during the evaluation phase will be similar to that in the
                training phase, with the exception that the ground truth files are missing.</p>

            <p><i>Details will be announced as soon as the dataset is ready.</i></p>

            <h2>Performance Measures</h2>
            <p>The performance of the submitted approaches will be ranked by a combined measure incorporating both the
                accuracy of distinguishing single- from multi-author documents and the correctness of the predicted number of authors.</p>
            <p><i>Details will be anounced soon.</i></p>

            <h2>Submission</h2>
            <p>We ask you to prepare your software so that it can be executed via command line calls. The
                command shall take as input (i) an absolute path to the directory of the evaluation corpus and
                (ii) an absolute path to an empty output directory:</p>
            <pre>mySoftware -i EVALUATION-DIRECTORY -o OUTPUT-DIRECTORY</pre>

            <p>Within <code>EVALUATION-DIRECTORY</code>, you will find a list of problem instances, i.e., <code>[filename].txt</code> files.
                For each problem instance you should produce the solution file <code>[filename].truth</code> in
                the <code>OUTPUT-DIRECTORY</code> For instance, you read <code>EVALUATION-DIRECTORY/problem-12.txt</code>,
                process it and write your results to <code>OUTPUT-DIRECTORY/problem-12.truth</code>.</p>

            <p>You can choose freely among the available programming languages and among the operating systems
                Microsoft Windows and Ubuntu. We will ask you to deploy your software onto a virtual machine
                that will be made accessible to you after registration. You will be able to reach the virtual
                machine via ssh and via remote desktop. More information about how to access the virtual
                machines can be found in the user guide below:</p>

            <p><a class="uk-button uk-button-primary" href="../../clef15/pan15-web/pan15-virtual-machine-user-guide.pdf">PAN Virtual
                Machine User Guide Â»</a></p>

            <p>Once deployed in your virtual machine, we ask you to access TIRA at <a href="http://www.tira.io">www.tira.io</a>,
                where you can self-evaluate your software on the test data.</p>

            <p><strong>Note:</strong> By submitting your software you retain full copyrights. You agree to grant
                us usage rights only for the purpose of the PAN competition. We agree not to share your software
                with a third party or use it for other purposes than the PAN competition.</p>

            <h2>Related Work</h2>
            <p>We refer you to:</p>
            <ul>
                <li>
                    <a href="../../clef18/pan18-web/proceedings.html">PAN@CLEF'18</a> (<i>Overview of the Author
                    Identification Task at PAN-2018: Cross-domain Authorship Attribution and Style Change Detection</i>)
                </li>
                <li>
                    <a href="../../clef17/pan17-web/proceedings.html">PAN@CLEF'17</a> (<i>Overview of the Author
                    Identification Task at PAN-2017</i> and <i>Style Breach Detection</i> section)
                </li>
                <li>
                    <a href="../../clef16/pan16-web/proceedings.html">PAN@CLEF'16</a> (<i>Clustering by
                    Authorship Within and Across Documents</i> and <i>Author Diarization</i> section)
                </li>
                <!--<li>Marti A. Hearst. <a href="http://anthology.aclweb.org/J/J97/J97-1003.pdf">TextTiling:
                    Segmenting Text into Multi-paragraph Subtopic Passages.</a>. In Computational Linguistics,
                    Volume 23, Issue 1, pages 33-64, 1997.
                </li>-->
                <li>Benno Stein, Nedim Lipka and Peter Prettenhofer. <a
                        href="https://www.uni-weimar.de/medien/webis/publications/papers/stein_2011a.pdf">Intrinsic
                    Plagiarism Analysis</a>. In Language Resources and Evaluation, Volume 45, Issue 1, pages
                    63â82, 2011.
                </li>
                <!--<li>
                    Patrick Juola.Â <a href="http://portal.acm.org/citation.cfm?id=1373451">Authorship
                    Attribution</a>. In Foundations and Trends in Information Retrieval, Volume 1, Issue 3,
                    March 2008.
                </li>-->
                <li>
                    Efstathios Stamatatos.Â <a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.21001/full">A
                    Survey of Modern Authorship Attribution Methods</a>.
                    Journal of the American Society for Information Science and Technology, Volume 60, Issue 3,
                    pages 538-556, March 2009.
                </li>
            </ul>
        </div>
    </div>

    <!-- Footer -->
    <footer class="uk-section uk-section-muted">
        <div class="uk-container">
            <h2>Task Chair</h2>
            <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                {% include people-cards/tschuggnall.html %}
            </div>
            <h2>Task Committee</h2>
            <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                {% include people-cards/specht.html %}
                {% include people-cards/potthast.html %}
                {% include people-cards/stein.html %}
            </div>
        </div>
        <div class="uk-container uk-padding-large uk-padding-remove-bottom">
            {% include organizations/pan19-organizations-section.html %}
        </div>
    </footer>
</main>
